{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'test_training_labels' from 'data.test_dataset' (/Users/brookeryan/Developer/BaldiLab/Visual-Acuity/data/test_dataset.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-30-1996132240e5>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mnumpy\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0mnp\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 3\u001B[0;31m \u001B[0;32mfrom\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_dataset\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mtest_training_labels\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      4\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mdata\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mDataset\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mpreprocessing\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconstants\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mTRAINING_PATH\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mTESTING_PATH\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'test_training_labels' from 'data.test_dataset' (/Users/brookeryan/Developer/BaldiLab/Visual-Acuity/data/test_dataset.py)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from data.test_dataset import test_training_labels\n",
    "from data.dataset import Dataset\n",
    "from preprocessing.constants import TRAINING_PATH, TESTING_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HI33316\n"
     ]
    }
   ],
   "source": [
    "print(\"HI33316\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset contains 8478 images\n",
      "SIZE =  8478\n",
      "Training Dataset contains 8255 images\n",
      "SIZE =  8255\n"
     ]
    }
   ],
   "source": [
    "training_dataset = Dataset(TRAINING_PATH, name=\"Training\", height=400, width=400, batch_size=30)\n",
    "testing_dataset = Dataset(TESTING_PATH, name=\"Training\", height=400, width=400, batch_size=30)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "training_dataset.process_labels()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'data.test_dataset' has no attribute 'test_training_labels'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-28-893065f37e23>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mtest_dataset\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtest_training_labels\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtraining_dataset\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mAttributeError\u001B[0m: module 'data.test_dataset' has no attribute 'test_training_labels'"
     ]
    }
   ],
   "source": [
    "test_training_labels(training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"~~~~~~~~~~~~\")\n",
    "print(\"    Test    \")\n",
    "print(\"~~~~~~~~~~~~\")\n",
    "print(\"y_test_optotype: \", testing_dataset.optotypes)\n",
    "print(\"y_test_angle: \", np.unique(training_dataset.angles))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def print_random_test_values(ax):\n",
    "    index = np.random.randint(0, x_test.shape[0])\n",
    "    print(\"~~~~~~~~~~~~\")\n",
    "    print(\"Test Values \")\n",
    "    print(\"~~~~~~~~~~~~\")\n",
    "\n",
    "    print(\"Index = {x}\".format(x=index))\n",
    "\n",
    "    print(\"Optotype = {x}\".format(x=y_test_optotype[index]))\n",
    "    print(\"Angle = {x}\".format(x=y_test_angle[index]))\n",
    "    print(x_test[index])\n",
    "\n",
    "    ax.set_title(\"Test- {x}\".format(x=y_test_optotype[index]))\n",
    "    ax.imshow(x_test[index])\n",
    "\n",
    "def print_random_training_values(ax):\n",
    "    index = np.random.randint(0, x_train.shape[0])\n",
    "    print(\"~~~~~~~~~~~~\")\n",
    "    print(\"Train Values\")\n",
    "    print(\"~~~~~~~~~~~~\")\n",
    "\n",
    "    print(\"Index = {x}\".format(x=index))\n",
    "\n",
    "    print(\"Optotype = {x}\".format(x=y_train_optotype[index]))\n",
    "    print(\"Angle = {x}\".format(x=y_train_angle[index]))\n",
    "    print(x_test[index])\n",
    "\n",
    "    ax.set_title(\"Train - {x}\".format(x=y_train_optotype[index]))\n",
    "    ax.imshow(x_train[index])\n",
    "\n",
    "fig, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
    "print_random_test_values(ax[0])\n",
    "print_random_training_values(ax[1])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Transfer learning\n",
    "\n",
    "## RESNET50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow import keras\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "TODO : Going to try this experiment with this guy https://github.com/EscVM/Efficient-CapsNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def testicle_test():\n",
    "    y_train_angle = np.zeros(27, dtype=np.int)\n",
    "    for i, sample_name in enumerate(low_distortion_filenames):\n",
    "        thing = extract_angle(sample_name)\n",
    "        y_train_angle[i] = thing\n",
    "    print(np.unique(y_train_angle))\n",
    "\n",
    "testicle_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Transfer learning with VGG16\n",
    "\n",
    "### Create the model\n",
    "- Make sure `model.trainable = False `\n",
    "-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "training_set = image_dataset_from_directory(\"/Users/brookeryan/Developer/BaldiLab/Visual-Acuity/images/training/\",\n",
    "                                             shuffle=True,\n",
    "                                             batch_size=32,\n",
    "                                             image_size=(150, 150))\n",
    "val_dataset = image_dataset_from_directory(\"/Users/brookeryan/Developer/BaldiLab/Visual-Acuity/images/testing/\",\n",
    "                                                  shuffle=True,\n",
    "                                                  batch_size=32,\n",
    "                                                  image_size=(150, 150))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def create_base_model():\n",
    "    vgg = VGG16(include_top=False, weights=\"imagenet\", input_shape=(h, w, 3))\n",
    "    vgg.trainable = False\n",
    "    return vgg\n",
    "\n",
    "base_model = create_base_model()\n",
    "x = base_model(x_train, training=False)\n",
    "x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "x = keras.layers.Dropout(0.2)(x)\n",
    "inputs = keras.Input(shape=(h, w, 3))\n",
    "outputs = keras.layers.Dense(1, activation=tf.keras.activations.softmax)(x)\n",
    "model = keras.Model(inputs, outputs)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(training_set, epochs=20, validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import ssl\n",
    "\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "# !pip install pydot\n",
    "# !pip install graphviz\n",
    "# !pip install pydotplus\n",
    "\n",
    "model = tf.keras.applications.VGG16()\n",
    "# plot_model(model)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from keras import  models\n",
    "\n",
    "base_model = VGG16(weights='imagenet')\n",
    "model_VGG16 = models.Model(inputs=base_model.input, outputs=base_model.get_layer('flatten').output)\n",
    "\n",
    "model_VGG16.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model = VGG16(include_top=False, weights=\"imagenet\", input_shape=(h, w, 3))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "for layer in model.layers[:45]:\n",
    "    layer.trainable = False\n",
    "    print(layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow.keras as K\n",
    "\n",
    "def create_transfer_model_2():\n",
    "    input_t = K.Input(shape=(h, w, 3))\n",
    "    res_model = K.applications.ResNet50(include_top=False,\n",
    "                                        weights=\"imagenet\",\n",
    "                                        input_tensor=input_t)\n",
    "\n",
    "    for layer in res_model.layers[:45]:\n",
    "        layer.trainable = False\n",
    "    #to_res = (224, 224)\n",
    "    model = K.models.Sequential()\n",
    "    #model.add(K.layers.Lambda(lambda image: tf.image.resize(image, to_res)))\n",
    "    model.add(res_model)\n",
    "    model.add(K.layers.Flatten())\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(256, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(128, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(64, activation='relu'))\n",
    "    model.add(K.layers.Dropout(0.5))\n",
    "    model.add(K.layers.BatchNormalization())\n",
    "    model.add(K.layers.Dense(4, activation='softmax')) #this\n",
    "\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n",
    "model = create_transfer_model_2()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-7f7be0b7",
   "language": "python",
   "display_name": "PyCharm (DeepRecognition)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}